# Retrieval-Enabled Agent Service

This service provides a retrieval-augmented question-answering system that uses OpenAI's Assistant API with a custom tool to retrieve relevant information from a vector database (Qdrant) containing book content.

## Architecture

The system consists of several key components:

- **FastAPI Application**: The main web server that handles incoming requests
- **Agent Service**: Orchestrates the OpenAI agent and manages conversations
- **Retrieval Tool**: Custom function that queries Qdrant using Cohere embeddings
- **Data Models**: Pydantic models for request/response validation
- **Configuration**: Management of API keys and settings

## Endpoints

### `/ask` (POST)
Ask questions about the book content and receive sourced answers.

Request:
```json
{
  "query": "string (required) - The question to ask",
  "session_id": "string (optional) - Session identifier for maintaining context",
  "user_id": "string (optional) - User identifier"
}
```

Response:
```json
{
  "response_id": "string",
  "answer": "string - The answer generated by the agent",
  "sources": [
    {
      "chunk_id": "string",
      "content": "string",
      "url": "string",
      "position": "integer",
      "relevance_score": "float",
      "source_metadata": "object"
    }
  ],
  "query_id": "string",
  "timestamp": "string",
  "confidence_score": "float (optional)"
}
```

### `/health` (GET)
Check the health status of the service and its dependencies.

Response:
```json
{
  "status": "string - Overall health status",
  "timestamp": "string - ISO 8601 formatted timestamp",
  "services": {
    "openai": {
      "status": "string",
      "response_time_ms": "number"
    },
    "qdrant": {
      "status": "string",
      "response_time_ms": "number"
    },
    "cohere": {
      "status": "string",
      "response_time_ms": "number"
    }
  },
  "details": {
    "uptime_seconds": "number",
    "active_sessions": "number",
    "version": "string"
  }
}
```

### `/agent/run` (POST)
Execute an agent run programmatically with custom instructions.

Request:
```json
{
  "instructions": "string (required) - Instructions for the agent",
  "input_data": "object (optional) - Additional data to provide to the agent",
  "session_id": "string (optional)",
  "tools": "array of strings (optional)",
  "model": "string (optional)"
}
```

Response:
```json
{
  "run_id": "string",
  "status": "string",
  "output": "string",
  "timestamp": "string",
  "execution_time_ms": "integer",
  "tool_calls": [
    {
      "tool_name": "string",
      "input": "object",
      "output": "object"
    }
  ]
}
```

## Environment Variables

The service requires the following environment variables:

- `OPENAI_API_KEY`: API key for OpenAI services
- `QDRANT_URL`: URL for the Qdrant vector database
- `QDRANT_API_KEY`: API key for Qdrant access
- `COHERE_API_KEY`: API key for Cohere services
- `QDRANT_COLLECTION_NAME`: Name of the collection in Qdrant (default: "reg-embedding")
- `AGENT_MODEL`: OpenAI model to use for the agent (default: "gpt-4-1106-preview")
- `COHERE_MODEL`: Cohere model to use for embeddings (default: "embed-multilingual-v3.0")
- `TOP_K_CHUNKS`: Number of top chunks to retrieve (default: 5)
- `TIMEOUT_SECONDS`: Request timeout in seconds (default: 10)
- `LOG_LEVEL`: Logging level (default: "INFO")

## Rate Limiting

The API implements rate limiting:
- `/ask`: 100 requests per minute per IP
- `/health`: 200 requests per minute per IP
- `/agent/run`: 50 requests per minute per IP

## Running the Service

To run the service:

1. Install dependencies:
   ```bash
   pip install -e .
   ```

2. Set up environment variables in a `.env` file or system environment

3. Start the server:
   ```bash
   cd backend
   uvicorn src.agent.main:app --reload --port 8000
   ```

## Testing

Unit tests are available in the `backend/tests/` directory:

- `test_models.py`: Tests for data models
- `test_retrieval_tool.py`: Tests for the retrieval tool
- `test_api.py`: API endpoint tests
- `test_agent.py`: Agent functionality tests

Run tests with:
```bash
cd backend
pytest tests/
```

## Error Handling

The service handles various error conditions:

- Network timeouts and connection errors to external services
- Invalid input validation
- API quota exceeded errors from external services
- Agent processing errors

All errors return appropriate HTTP status codes and descriptive error messages.

## Logging

The service logs important events including:

- Agent interactions (Agent → Tool → Agent flow)
- API requests and responses
- Errors and exceptional conditions
- Service health status

Logs follow a structured format with request and session IDs for easy correlation.